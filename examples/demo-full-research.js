/**
 * Full Research Demo with Tavily Web Search
 * This demonstrates complete research with real web search capabilities
 */

const { 
  GPTResearch,
  Config,
  Memory,
  ResearchConductor,
  ReportGenerator,
  ContextManager,
  BrowserManager,
  SourceCurator,
  RetrieverFactory,
  TavilyRetriever,
  LLMProviderFactory,
  OpenAIProvider,
  ReportType,
  Tone,
  ConsoleOutput
} = require('./dist');
const dotenv = require('dotenv');

// Load environment variables
dotenv.config();

// Register providers
LLMProviderFactory.register('openai', OpenAIProvider);
RetrieverFactory.register('tavily', TavilyRetriever);

async function runFullResearch() {
  console.log('\nüåê GPT RESEARCHER - FULL WEB RESEARCH DEMO\n');
  console.log('=' .repeat(60));
  
  // Check for API keys
  if (!process.env.OPENAI_API_KEY) {
    console.error('‚ùå OPENAI_API_KEY not found in .env');
    return;
  }
  if (!process.env.TAVILY_API_KEY) {
    console.error('‚ùå TAVILY_API_KEY not found in .env');
    return;
  }
  
  console.log('‚úÖ OpenAI API key loaded');
  console.log('‚úÖ Tavily API key loaded');
  console.log('\nüìù Research Query: "What are the latest developments in AI in 2024?"\n');
  
  try {
    // Initialize configuration
    const config = Config.getInstance({
      query: 'What are the latest developments in AI in 2024?',
      reportType: ReportType.DetailedReport,
      tone: Tone.Professional,
      llmProvider: 'openai',
      smartLLMModel: 'gpt-3.5-turbo',
      fastLLMModel: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 1500,
      retrievers: ['tavily'],
      maxSearchResults: 5,
      apiKeys: {
        openai: process.env.OPENAI_API_KEY,
        tavily: process.env.TAVILY_API_KEY
      }
    });
    
    const memory = new Memory();
    
    // Initialize LLM provider
    const llmProvider = LLMProviderFactory.create('openai', {
      apiKey: process.env.OPENAI_API_KEY
    });
    
    // Initialize skills
    const researchConductor = new ResearchConductor(config, memory);
    const contextManager = new ContextManager(config, memory);
    const browserManager = new BrowserManager(config, memory);
    const sourceCurator = new SourceCurator(config, memory);
    const reportGenerator = new ReportGenerator(config, memory);
    
    console.log('üîÑ Starting comprehensive research process...\n');
    const startTime = Date.now();
    
    // Step 1: Plan the research
    console.log('üìã Step 1: Planning research outline...');
    const researchPlan = await researchConductor.planResearch(
      'What are the latest developments in AI in 2024?',
      llmProvider
    );
    console.log(`   ‚úÖ Generated ${researchPlan.questions.length} research questions`);
    console.log(`   üìù Questions:`, researchPlan.questions.slice(0, 3).map(q => `\n      - ${q}`).join(''));
    
    // Step 2: Search the web
    console.log('\nüîé Step 2: Searching the web with Tavily...');
    const searchResults = await researchConductor.conductSearch(
      researchPlan.questions,
      llmProvider
    );
    console.log(`   ‚úÖ Found ${searchResults.totalResults} search results`);
    console.log(`   üåê Unique URLs: ${searchResults.uniqueUrls}`);
    
    // Step 3: Build context
    console.log('\nüìö Step 3: Building research context...');
    const context = await contextManager.buildContext(
      searchResults.results,
      llmProvider
    );
    console.log(`   ‚úÖ Built ${context.items.length} context items`);
    console.log(`   üìä Total tokens: ${context.totalTokens}`);
    
    // Step 4: Validate sources
    console.log('\n‚úîÔ∏è  Step 4: Validating sources...');
    const validatedSources = await sourceCurator.validateSources(
      searchResults.results,
      llmProvider
    );
    console.log(`   ‚úÖ Trusted sources: ${validatedSources.trusted.length}`);
    console.log(`   ‚ö†Ô∏è  Blocked sources: ${validatedSources.blocked.length}`);
    
    // Step 5: Generate report
    console.log('\n‚úçÔ∏è  Step 5: Generating comprehensive report...');
    const researchContext = {
      query: config.get('query'),
      reportType: config.get('reportType'),
      findings: context.items.map(item => item.content),
      sources: validatedSources.trusted.map(s => ({
        url: s.url,
        title: s.title,
        relevance: s.relevance
      })),
      subtopics: researchPlan.subtopics || []
    };
    
    const report = await reportGenerator.generateReport(researchContext, llmProvider);
    
    const duration = Date.now() - startTime;
    
    // Display results
    console.log('\n' + '=' .repeat(60));
    console.log('\nüìÑ RESEARCH REPORT:\n');
    console.log(report.substring(0, 2000)); // Show first 2000 chars
    if (report.length > 2000) {
      console.log('\n... [Report truncated for display, full length: ' + report.length + ' characters]');
    }
    
    // Show sources
    console.log('\n' + '=' .repeat(60));
    console.log('\nüìö SOURCES USED:\n');
    validatedSources.trusted.slice(0, 5).forEach((source, i) => {
      console.log(`  ${i + 1}. ${source.title}`);
      console.log(`     URL: ${source.url}`);
      console.log(`     Relevance: ${(source.relevance * 100).toFixed(0)}%`);
    });
    
    // Calculate costs
    const estimatedTokens = (researchPlan.questions.length * 100) + // Planning
                           (searchResults.totalResults * 50) + // Search processing
                           context.totalTokens + // Context
                           (report.length / 4); // Report generation
    const estimatedCost = (estimatedTokens / 1000) * 0.002; // GPT-3.5-turbo pricing
    
    console.log('\n' + '=' .repeat(60));
    console.log('\nüìä RESEARCH STATISTICS:\n');
    console.log(`  ‚Ä¢ Research Questions: ${researchPlan.questions.length}`);
    console.log(`  ‚Ä¢ Search Results: ${searchResults.totalResults}`);
    console.log(`  ‚Ä¢ Unique URLs: ${searchResults.uniqueUrls}`);
    console.log(`  ‚Ä¢ Context Items: ${context.items.length}`);
    console.log(`  ‚Ä¢ Trusted Sources: ${validatedSources.trusted.length}`);
    console.log(`  ‚Ä¢ Report Length: ${report.length} characters`);
    console.log(`  ‚Ä¢ Total Duration: ${(duration / 1000).toFixed(2)} seconds`);
    console.log(`  ‚Ä¢ Estimated Tokens: ~${Math.round(estimatedTokens)}`);
    console.log(`  ‚Ä¢ Estimated Cost: ~$${estimatedCost.toFixed(4)}`);
    
    // Memory stats
    const memoryStats = memory.getStats();
    console.log('\nüíæ Memory Statistics:');
    console.log(`  ‚Ä¢ Search Queries: ${memoryStats.searchQueries}`);
    console.log(`  ‚Ä¢ Search Results: ${memoryStats.searchResults}`);
    console.log(`  ‚Ä¢ Context Items: ${memoryStats.contextItems}`);
    console.log(`  ‚Ä¢ Subtopics: ${memoryStats.subtopics}`);
    
    console.log('\n‚ú® Full web research completed successfully!');
    console.log('\nüéØ This demonstrates:');
    console.log('  ‚úì Real-time web search with Tavily');
    console.log('  ‚úì Multi-step research workflow');
    console.log('  ‚úì Source validation and curation');
    console.log('  ‚úì Context building and summarization');
    console.log('  ‚úì Professional report generation');
    
  } catch (error) {
    console.error('\n‚ùå Error during research:', error.message);
    
    if (error.message.includes('401')) {
      console.log('\n‚ö†Ô∏è  Authentication error - please check your API keys');
    } else if (error.message.includes('429')) {
      console.log('\n‚ö†Ô∏è  Rate limit exceeded - please wait and try again');
    } else {
      console.log('\nüí° Debug info:', error.stack);
    }
  }
}

// Alternative: Use the high-level GPTResearch API
async function runSimpleResearch() {
  console.log('\nüöÄ SIMPLE API DEMO - Using GPTResearch Class\n');
  console.log('=' .repeat(60));
  
  try {
    const researcher = new GPTResearch({
      query: 'What are the benefits of TypeScript over JavaScript?',
      reportType: ReportType.QuickSummary,
      tone: Tone.Casual,
      llmProvider: 'openai',
      smartLLMModel: 'gpt-3.5-turbo',
      retrievers: ['tavily'],
      maxSearchResults: 3,
      apiKeys: {
        openai: process.env.OPENAI_API_KEY,
        tavily: process.env.TAVILY_API_KEY
      }
    });
    
    console.log('üîÑ Conducting research with web search...\n');
    const result = await researcher.conductResearch();
    
    console.log('üìÑ Report:\n');
    console.log(result.report);
    
    console.log('\nüìä Summary:');
    console.log(`  ‚Ä¢ Sources found: ${result.sources.length}`);
    console.log(`  ‚Ä¢ Total cost: $${result.costs.total.toFixed(4)}`);
    console.log(`  ‚Ä¢ Duration: ${(result.metadata.duration / 1000).toFixed(2)} seconds`);
    
  } catch (error) {
    console.error('‚ùå Error:', error.message);
  }
}

// Main execution
async function main() {
  console.log('üéâ GPT Research with Tavily Web Search');
  console.log('=' .repeat(60));
  
  const choice = process.argv[2] || 'full';
  
  if (choice === 'simple') {
    await runSimpleResearch();
  } else {
    await runFullResearch();
  }
  
  console.log('\n‚úÖ Demo completed successfully!');
  console.log('\nüìö Try different modes:');
  console.log('  node demo-full-research.js       # Full detailed demo (default)');
  console.log('  node demo-full-research.js simple # Simple API demo');
}

main().catch(error => {
  console.error('\n‚ùå Demo failed:', error);
  process.exit(1);
});
